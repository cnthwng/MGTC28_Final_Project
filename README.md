# MGTC28_Final_Project
## *Project Description*
The project contains the coding scripts, in Jupyter Notebook format, used to organize, visualize, and combine the five datasets provided. This was achieved by utilizing the **pandas library** to clean and combine all the datasets. Additionally, the **seaborn library** & **matplotlib library** were used to visualize the data from the data frames. After our initial analysis, a single data frame containing all formatted data was exported as a CSV file to Tableau for additional data visualization and trend analysis.  

<br/> 
  
#### *Documentation for Libraries Used:*
* [pandas](https://pandas.pydata.org/docs)
* [seaborn](https://seaborn.pydata.org)
* [matplotlib](https://matplotlib.org/stable/index.html)

<br/> 
<br/> 

## *Organization of Repository*
This repository contains the following directories:
* **data/** Consists of two subdirectories: 1) Contains all raw data files provided. 2) Contains a file with all of the cleaned data in CSV format.
* **script/** Contains a subdirectory "Analysis & Plots" which contains the Jupyter Notebook files for the initial analysis and plotting for each CSV file with the raw data provided. This initial analysis provided the team with additional context which assisted in drafting the Project Plan. The Jupyter Notebook file "Data Cleaning & Combining" outlines the script used to create a CSV file containing all data from the different files formatted consistently. This was the file exported to Tableau.
* **documents/** Contains a markdown file which outlines the Project Plan

	


<br/> 

## *Part 1: Project Plan*

**Overview of Approach:** We plan to approach this project by first reviewing and cleaning the five datasets provided to identify any trends. We have created a GitHub repository to add all of the code and data analyses conducted by our team members, which will help facilitate collaboration throughout this project. 
	The members of this group include Athena, Cynthia, and Monica. The initial division of labor involves distributing the five different datasets among the three of us to create preliminary data visualizations. The preliminary analyses will help us determine the dataset(s) we will focus on and choose a Need State to further examine. After determining our Need State and datasets of interest, we will conduct additional analyses to create a go-to market strategy with recommendations. All of our members will be involved in the coding of this project, as well as the creation of the slides and delivery of the final presentation. 

From our preliminary analyses, we found that Need States 1 and  5 had the most prominent seasonal consumer purchase trends as they both showcased an immense increase in Factory POS (Point of Sales in Factory $) during the warmer seasons. Additionally, for Total Sales made to retailers, both Need State 1 and 5 had a greater sales volume compared to the other Need States. This trend was consistently observed for the past three years. The Customer Distribution Center Inventory Amount analysis produced a notable decline in inventory levels across all Need States between weeks 42 and 50. This may be attributed to seasonal demand shifts, supply chain disruptions, and/or end-of-year sales. 

**External Data:** Moving forward, we plan to extract external data from Passport GMID, which provides statistics and qualitative reports of consumer markets. This database allows us to conduct analyses on specific sectors like ‘Consumer Health Canada’ and various product types, which will help provide deeper insights. We will also explore other online data sources such as SimplyAnalytics.

**Technologies Involved:** Technologies we will utilize include Python software (through Jupyter Notebook), GitHub, PowerPoint, and potentially Tableau. Specific libraries we will use include Pandas, to assist in automating data manipulations for the different datasets provided. Pandas’ statistical functions would allow ease in sorting and organizing the data, making it easier to work with the various variables provided. Another library we will use is Seaborn, to help visualize the information from the dataframes created. Seaborn enables us to gain insights into relationships within variables and identify trends within the data. 

 
 For next steps, we have decided to move forward with either Need State 1 or 5, the Need States we have observed the most trends from. We will combine the datasets for the chosen Need State and obtain external data to conduct additional analyses to inform our recommendations. From our initial observations, there is a seasonality component for these Need States so our recommendations will likely involve decisions Kenvue can make to optimize trade spend on products and sales made to retailers, within particular periods. 

